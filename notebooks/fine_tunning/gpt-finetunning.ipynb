{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, TextDataset,DataCollatorForLanguageModeling, AutoConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import datasets as ds\n",
    "import torch\n",
    "import re\n",
    "\n",
    "data = pd.read_csv(\"../data/processed/context_reply_pairs.csv\", sep=\";\")\n",
    "\n",
    "train = data[data['split'] == 'train']\n",
    "test = data[data['split'] == 'test']\n",
    "val = data[data['split'] == 'val']\n",
    "\n",
    "train.to_csv(\"../data/gpt/train_2.csv\", index=False)\n",
    "test.to_csv(\"../data/gpt/test_2.csv\", index=False)\n",
    "val.to_csv(\"../data/gpt/val_2.csv\", index=False)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cjvt/gpt-sl-base\", truncation=True, truncation_side='left')\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"cjvt/gpt-sl-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "     \n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)   \n",
    "    \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator\n",
    "\n",
    "train_dataset, eval_dataset, data_collator = load_dataset(\"../data/gpt/train_2.csv\",\"../data/gpt/eval_2.csv\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/gpt-ft-2\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=1, # number of training epochs\n",
    "    per_device_train_batch_size=8, # batch size for training\n",
    "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "    eval_steps = 400, # Number of update steps between two evaluations.\n",
    "    save_steps = 800, # after # steps model is saved \n",
    "    warmup_steps = 500,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy = \"no\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds_2\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5a0312fc8342c9815e267dc1deadc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7504, 'learning_rate': 5e-05, 'epoch': 0.03}\n",
      "{'loss': 2.5868, 'learning_rate': 4.8483009708737866e-05, 'epoch': 0.06}\n",
      "{'loss': 2.53, 'learning_rate': 4.696601941747573e-05, 'epoch': 0.09}\n",
      "{'loss': 2.4703, 'learning_rate': 4.544902912621359e-05, 'epoch': 0.12}\n",
      "{'loss': 2.4347, 'learning_rate': 4.393203883495146e-05, 'epoch': 0.15}\n",
      "{'loss': 2.3789, 'learning_rate': 4.2415048543689325e-05, 'epoch': 0.18}\n",
      "{'loss': 2.3514, 'learning_rate': 4.089805825242719e-05, 'epoch': 0.21}\n",
      "{'loss': 2.3267, 'learning_rate': 3.938106796116505e-05, 'epoch': 0.24}\n",
      "{'loss': 2.2705, 'learning_rate': 3.7864077669902914e-05, 'epoch': 0.27}\n",
      "{'loss': 2.2519, 'learning_rate': 3.634708737864078e-05, 'epoch': 0.29}\n",
      "{'loss': 2.2323, 'learning_rate': 3.483009708737864e-05, 'epoch': 0.32}\n",
      "{'loss': 2.2026, 'learning_rate': 3.3313106796116504e-05, 'epoch': 0.35}\n",
      "{'loss': 2.1608, 'learning_rate': 3.1796116504854373e-05, 'epoch': 0.38}\n",
      "{'loss': 2.1502, 'learning_rate': 3.0279126213592237e-05, 'epoch': 0.41}\n",
      "{'loss': 2.1364, 'learning_rate': 2.8762135922330096e-05, 'epoch': 0.44}\n",
      "{'loss': 2.1214, 'learning_rate': 2.7245145631067963e-05, 'epoch': 0.47}\n",
      "{'loss': 2.0997, 'learning_rate': 2.5728155339805826e-05, 'epoch': 0.5}\n",
      "{'loss': 2.0628, 'learning_rate': 2.4211165048543692e-05, 'epoch': 0.53}\n",
      "{'loss': 2.0564, 'learning_rate': 2.2694174757281556e-05, 'epoch': 0.56}\n",
      "{'loss': 2.0569, 'learning_rate': 2.117718446601942e-05, 'epoch': 0.59}\n",
      "{'loss': 2.0315, 'learning_rate': 1.9660194174757282e-05, 'epoch': 0.62}\n",
      "{'loss': 2.0144, 'learning_rate': 1.814320388349515e-05, 'epoch': 0.65}\n",
      "{'loss': 1.9913, 'learning_rate': 1.662621359223301e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9684, 'learning_rate': 1.5109223300970873e-05, 'epoch': 0.71}\n",
      "{'loss': 1.9473, 'learning_rate': 1.3592233009708738e-05, 'epoch': 0.74}\n",
      "{'loss': 1.9632, 'learning_rate': 1.2075242718446603e-05, 'epoch': 0.77}\n",
      "{'loss': 1.9577, 'learning_rate': 1.0558252427184466e-05, 'epoch': 0.8}\n",
      "{'loss': 1.9346, 'learning_rate': 9.04126213592233e-06, 'epoch': 0.82}\n",
      "{'loss': 1.9325, 'learning_rate': 7.524271844660194e-06, 'epoch': 0.85}\n",
      "{'loss': 1.9126, 'learning_rate': 6.0072815533980584e-06, 'epoch': 0.88}\n",
      "{'loss': 1.902, 'learning_rate': 4.490291262135922e-06, 'epoch': 0.91}\n",
      "{'loss': 1.8891, 'learning_rate': 2.973300970873787e-06, 'epoch': 0.94}\n",
      "{'loss': 1.8885, 'learning_rate': 1.4563106796116506e-06, 'epoch': 0.97}\n",
      "{'train_runtime': 2798.3903, 'train_samples_per_second': 48.54, 'train_steps_per_second': 6.068, 'train_loss': 2.1425422551634736, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16980, training_loss=2.1425422551634736, metrics={'train_runtime': 2798.3903, 'train_samples_per_second': 48.54, 'train_steps_per_second': 6.068, 'train_loss': 2.1425422551634736, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenizer\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cjvt/gpt-sl-base\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"..\\models\\gpt-ft-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../data/gpt/test.csv\").head(n = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens = test_data[\"prompt\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = tokenizer(sens, return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  gen_tokens = model.generate(\n",
    "      **prompts,\n",
    "      do_sample=False,\n",
    "      max_new_tokens=50,\n",
    "  )\n",
    "gen_text = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n",
    "gen_text = [re.sub('[^a-zA-Z0-9čšž\\ \\.!?,]+', '', _) for _ in gen_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"generated\"] = gen_text\n",
    "test_data.to_csv(\"../data/gpt_results/test_with_generated_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Povej mi več o neumnem, neumnem Elonu Musku in njegovih neumnih dogodivščinah nakupa Twitterja.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"prompt\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Povej mi več o neumnem, neumnem Elonu Musku in njegovih neumnih dogodivščinah nakupa Twitterja.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"generated\"][10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
