{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Finetuning T5-sl-small on Oasst1-sl\n\nCode adapted from [Fine-Tune T5 ü§ó for Conversational Model](https://www.kaggle.com/code/kreeshrajani/fine-tune-t5-for-conversational-model)","metadata":{}},{"cell_type":"code","source":"import json\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport pandas as pd\nimport pytorch_lightning as pl\nfrom torch.nn.utils.rnn import pad_sequence\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom transformers import AutoTokenizer, T5ForConditionalGeneration, AdamW","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-13T11:35:03.942632Z","iopub.execute_input":"2023-05-13T11:35:03.943246Z","iopub.status.idle":"2023-05-13T11:35:20.105650Z","shell.execute_reply.started":"2023-05-13T11:35:03.943201Z","shell.execute_reply":"2023-05-13T11:35:20.104714Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nINPUT_MAX_LEN = 512 #input length\nOUTPUT_MAX_LEN = 512 # output length\nTRAIN_BATCH_SIZE = 8 # batch size of training\nVAL_BATCH_SIZE = 2 # batch size for validation\nEPOCHS = 5 # number of epoch\nMODEL_NAME = \"cjvt/t5-sl-small\"","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:20.107487Z","iopub.execute_input":"2023-05-13T11:35:20.107816Z","iopub.status.idle":"2023-05-13T11:35:20.128230Z","shell.execute_reply.started":"2023-05-13T11:35:20.107785Z","shell.execute_reply":"2023-05-13T11:35:20.127428Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/oasst1-sl/google_translate.jsonl'\nwith open(data_path, 'r') as f:\n    data = [json.loads(line) for line in f]","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:20.129489Z","iopub.execute_input":"2023-05-13T11:35:20.130222Z","iopub.status.idle":"2023-05-13T11:35:24.809498Z","shell.execute_reply.started":"2023-05-13T11:35:20.130189Z","shell.execute_reply":"2023-05-13T11:35:24.808457Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:24.812129Z","iopub.execute_input":"2023-05-13T11:35:24.812517Z","iopub.status.idle":"2023-05-13T11:35:26.247759Z","shell.execute_reply.started":"2023-05-13T11:35:24.812481Z","shell.execute_reply":"2023-05-13T11:35:26.246788Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88ce918b2ff447dae9b1dc855bfba9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/797k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa540079a355440ba06f9ebd188409ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)/main/tokenizer.json:   0%|          | 0.00/2.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fff12b31cd2f4603a36c620f5c054248"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee4e58c265c641aea5be1f90675c3f84"}},"metadata":{}}]},{"cell_type":"code","source":"text = data[0]['prompt']['translation']    # assume the text that is to be tokenized \n\ninput_tokenize = tokenizer( \n             text,\n            add_special_tokens=True,        #Add Special tokens like [CLS] and [SEP]\n            max_length=INPUT_MAX_LEN,\n            padding = 'max_length',         #for padding to max_length for equal sequence length\n            truncation = True,              #truncate the text if it is greater than max_length\n            return_attention_mask=True,     #will return attention mask\n            return_tensors=\"pt\"             #return tensor formate\n        )","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:26.249146Z","iopub.execute_input":"2023-05-13T11:35:26.249599Z","iopub.status.idle":"2023-05-13T11:35:26.258827Z","shell.execute_reply.started":"2023-05-13T11:35:26.249566Z","shell.execute_reply":"2023-05-13T11:35:26.257931Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"text, input_tokenize['input_ids'].shape","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:26.260490Z","iopub.execute_input":"2023-05-13T11:35:26.260861Z","iopub.status.idle":"2023-05-13T11:35:26.270235Z","shell.execute_reply.started":"2023-05-13T11:35:26.260819Z","shell.execute_reply":"2023-05-13T11:35:26.269143Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('Ali imate kak≈°ne informacije o Commodore 64?', torch.Size([1, 512]))"},"metadata":{}}]},{"cell_type":"code","source":"def tree_to_pairs(tree):\n    # get pairs for root prompt and replies\n    pairs = message_to_pairs(tree[\"prompt\"])\n    return pairs\n\ndef message_to_pairs(message):\n    pairs = []\n    # check who is the input role (we want only pairs where the input is the prompter)\n    input_text = message['translation']\n    # check if we have any replies to build pairs from\n    if 'replies' in message:\n        for reply in message['replies']:\n            # get pairs for current input text ang reply\n            if 'translation' not in reply:\n                continue\n            pairs.append((input_text, reply['translation'], reply['role']))\n            # get pairs for reply and its replies\n            pairs.extend(message_to_pairs(reply))\n    return pairs","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:26.271721Z","iopub.execute_input":"2023-05-13T11:35:26.272176Z","iopub.status.idle":"2023-05-13T11:35:26.279783Z","shell.execute_reply.started":"2023-05-13T11:35:26.272145Z","shell.execute_reply":"2023-05-13T11:35:26.278613Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"pairs = []\nfor tree in data:\n    pairs += tree_to_pairs(tree)\npairs_df = pd.DataFrame(pairs, columns=['question', 'answer', 'reply_role'])\n\nmask = pairs_df['reply_role'] == \"assistant\"\npairs_df = pairs_df[mask]\npairs_df.drop(columns=['reply_role'], inplace=True)\ndisplay(pairs_df)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:26.281320Z","iopub.execute_input":"2023-05-13T11:35:26.281699Z","iopub.status.idle":"2023-05-13T11:35:26.467334Z","shell.execute_reply.started":"2023-05-13T11:35:26.281668Z","shell.execute_reply":"2023-05-13T11:35:26.466365Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                question  \\\n0           Ali imate kak≈°ne informacije o Commodore 64?   \n1           Ali imate kak≈°ne informacije o Commodore 64?   \n7           Ali imate kak≈°ne informacije o Commodore 64?   \n9           Ali imate kak≈°ne informacije o Commodore 64?   \n16     Metoda DMAIC v akciji\\nProduktna skupina opa≈æa...   \n...                                                  ...   \n67035                Katere jezike govorijo v Kostariki?   \n67036                Katere jezike govorijo v Kostariki?   \n67037                     Kaj je umetna nevronska mre≈æa?   \n67038                     Kaj je umetna nevronska mre≈æa?   \n67039                     Kaj je umetna nevronska mre≈æa?   \n\n                                                  answer  \n0      Seveda. Commodore 64 je 8-bitni domaƒçi raƒçunal...  \n1      Seveda, tukaj je kratek povzetek trenutnega ƒçl...  \n7      Commodore 64 (C64) je 8-bitni domaƒçi raƒçunalni...  \n9                      ja Bi ≈°e kaj posebej radi vedeli?  \n16     Metoda DMAIC (Define, Measure, Analyze, Improv...  \n...                                                  ...  \n67035  Primarni jezik, ki se govori v Kostariki, je ≈°...  \n67036  Uradni nacionalni jezik Kostarike je ≈°pan≈°ƒçina...  \n67037  Umetna nevronska mre≈æa (ANN) je raƒçunalni≈°ki m...  \n67038  Umetna nevronska mre≈æa je raƒçunalni≈°ki model, ...  \n67039  Umetna nevronska mre≈æa je kot umetni mo≈ægani, ...  \n\n[47514 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ali imate kak≈°ne informacije o Commodore 64?</td>\n      <td>Seveda. Commodore 64 je 8-bitni domaƒçi raƒçunal...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ali imate kak≈°ne informacije o Commodore 64?</td>\n      <td>Seveda, tukaj je kratek povzetek trenutnega ƒçl...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Ali imate kak≈°ne informacije o Commodore 64?</td>\n      <td>Commodore 64 (C64) je 8-bitni domaƒçi raƒçunalni...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Ali imate kak≈°ne informacije o Commodore 64?</td>\n      <td>ja Bi ≈°e kaj posebej radi vedeli?</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Metoda DMAIC v akciji\\nProduktna skupina opa≈æa...</td>\n      <td>Metoda DMAIC (Define, Measure, Analyze, Improv...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67035</th>\n      <td>Katere jezike govorijo v Kostariki?</td>\n      <td>Primarni jezik, ki se govori v Kostariki, je ≈°...</td>\n    </tr>\n    <tr>\n      <th>67036</th>\n      <td>Katere jezike govorijo v Kostariki?</td>\n      <td>Uradni nacionalni jezik Kostarike je ≈°pan≈°ƒçina...</td>\n    </tr>\n    <tr>\n      <th>67037</th>\n      <td>Kaj je umetna nevronska mre≈æa?</td>\n      <td>Umetna nevronska mre≈æa (ANN) je raƒçunalni≈°ki m...</td>\n    </tr>\n    <tr>\n      <th>67038</th>\n      <td>Kaj je umetna nevronska mre≈æa?</td>\n      <td>Umetna nevronska mre≈æa je raƒçunalni≈°ki model, ...</td>\n    </tr>\n    <tr>\n      <th>67039</th>\n      <td>Kaj je umetna nevronska mre≈æa?</td>\n      <td>Umetna nevronska mre≈æa je kot umetni mo≈ægani, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>47514 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class T5Dataset:\n    \n  def __init__(self,question,answer):   \n    \n    self.question = question\n    self.answer = answer\n    self.tokenizer = tokenizer\n    self.input_max_len = INPUT_MAX_LEN\n    self.output_max_len = OUTPUT_MAX_LEN\n  \n  def __len__(self):                      # This method retrives the number of item from the dataset\n    return len(self.question)\n\n  def __getitem__(self,item):             # This method retrieves the item at the specified index item. \n\n    question = str(self.question[item])\n    question = ''.join(question.split())\n\n    answer = str(self.answer[item])\n    answer = ''.join(answer.split())\n\n    input_tokenize = self.tokenizer(      \n            question,\n            add_special_tokens=True,\n            max_length=self.input_max_len,\n            padding = 'max_length',\n            truncation = True,\n            return_attention_mask=True,\n            return_tensors=\"pt\"\n        )\n    output_tokenize = self.tokenizer(\n            answer,\n            add_special_tokens=True,\n            max_length=self.output_max_len,\n            padding = 'max_length',\n            truncation = True,\n            return_attention_mask=True,\n            return_tensors=\"pt\"\n            \n        )\n    \n\n    input_ids = input_tokenize[\"input_ids\"].flatten()\n    attention_mask = input_tokenize[\"attention_mask\"].flatten()\n    labels = output_tokenize['input_ids'].flatten()\n\n    out = {\n            'question':question,      \n            'answer':answer,\n            'input_ids': input_ids,\n            'attention_mask':attention_mask,\n            'target':labels\n        }\n        \n    return out      ","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:26.469121Z","iopub.execute_input":"2023-05-13T11:35:26.469534Z","iopub.status.idle":"2023-05-13T11:35:26.480275Z","shell.execute_reply.started":"2023-05-13T11:35:26.469499Z","shell.execute_reply":"2023-05-13T11:35:26.479354Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class T5DataLoad(pl.LightningDataModule):\n    \n    def __init__(self,df_train,df_test):\n        super().__init__()\n        self.df_train = df_train\n        self.df_test = df_test\n        self.tokenizer = tokenizer\n        self.input_max_len = INPUT_MAX_LEN\n        self.out_max_len = OUTPUT_MAX_LEN\n    \n    def setup(self, stage=None):\n        \n        self.train_data = T5Dataset(\n            question = self.df_train.question.values,\n            answer = self.df_train.answer.values\n        )\n        \n        self.valid_data = T5Dataset(\n            question = self.df_test.question.values,\n            answer = self.df_test.answer.values\n        )\n    def train_dataloader(self):\n        return torch.utils.data.DataLoader(\n         self.train_data,\n         batch_size= TRAIN_BATCH_SIZE,\n         shuffle=True, \n         num_workers=2\n        )\n    def val_dataloader(self):\n        return torch.utils.data.DataLoader(\n        self.valid_data,\n        batch_size= VAL_BATCH_SIZE,\n        num_workers = 2\n        )\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:26.484119Z","iopub.execute_input":"2023-05-13T11:35:26.485301Z","iopub.status.idle":"2023-05-13T11:35:26.494735Z","shell.execute_reply.started":"2023-05-13T11:35:26.485263Z","shell.execute_reply":"2023-05-13T11:35:26.493594Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class T5Model(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict = True)\n\n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        \n        output = self.model(\n        input_ids=input_ids, \n        attention_mask=attention_mask, \n        labels=labels\n        )\n        return output.loss, output.logits\n    \n    def training_step(self, batch, batch_idx):\n\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        labels= batch[\"target\"]\n        loss, logits = self(input_ids , attention_mask, labels)\n\n        \n        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n\n        return {'loss': loss}\n    \n    def validation_step(self, batch, batch_idx):\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        labels= batch[\"target\"]\n        loss, logits = self(input_ids, attention_mask, labels)\n\n        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n        \n        return {'val_loss': loss}\n\n    def configure_optimizers(self):\n        return AdamW(self.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:26.496329Z","iopub.execute_input":"2023-05-13T11:35:26.496695Z","iopub.status.idle":"2023-05-13T11:35:26.508974Z","shell.execute_reply.started":"2023-05-13T11:35:26.496661Z","shell.execute_reply":"2023-05-13T11:35:26.508032Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def run():\n    df_train, df_test = train_test_split(pairs_df,test_size = 0.2, random_state=100)\n    dataload = T5DataLoad(df_train,df_test)\n    dataload.setup()\n    device = DEVICE\n    model = T5Model()\n    #model.to(device)\n    \n    checkpoint = ModelCheckpoint(\n        dirpath=\"/kaggle/working\",\n        filename='best-model',\n        save_top_k=2,\n        verbose=True,\n        monitor=\"val_loss\",\n        mode=\"min\"\n    )\n    trainer = pl.Trainer(\n        callbacks = checkpoint,\n        max_epochs= 1,\n        devices=2,\n        accelerator=\"auto\"\n    )\n    trainer.fit(model, dataload)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:26.510287Z","iopub.execute_input":"2023-05-13T11:35:26.510730Z","iopub.status.idle":"2023-05-13T11:35:26.521599Z","shell.execute_reply.started":"2023-05-13T11:35:26.510701Z","shell.execute_reply":"2023-05-13T11:35:26.520631Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"run()","metadata":{"execution":{"iopub.status.busy":"2023-05-13T11:35:26.523903Z","iopub.execute_input":"2023-05-13T11:35:26.524683Z","iopub.status.idle":"2023-05-13T12:09:48.358825Z","shell.execute_reply.started":"2023-05-13T11:35:26.524627Z","shell.execute_reply":"2023-05-13T12:09:48.357641Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e5e4ebe33e64fffa3bbec27b03773d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/307M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f2e35b6174641e4a960442ab5a04315"}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /kaggle/working exists and is not empty.\n  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:432: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n  warning_cache.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c852247fc444715af569c51a165cdd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"train_model = T5Model.load_from_checkpoint('/kaggle/working/best-model.ckpt')\ntrain_model.freeze()\n\ndef generate_question(question):\n\n    inputs_encoding =  tokenizer(\n        question,\n        add_special_tokens=True,\n        max_length= INPUT_MAX_LEN,\n        padding = 'max_length',\n        truncation='only_first',\n        return_attention_mask=True,\n        return_tensors=\"pt\"\n        )\n\n    \n    generate_ids = train_model.model.generate(\n        input_ids = inputs_encoding[\"input_ids\"],\n        attention_mask = inputs_encoding[\"attention_mask\"],\n        max_length = INPUT_MAX_LEN,\n        num_beams = 4,\n        num_return_sequences = 1,\n        no_repeat_ngram_size=2,\n        early_stopping=True,\n        )\n\n    preds = [\n        tokenizer.decode(gen_id,\n        skip_special_tokens=True, \n        clean_up_tokenization_spaces=True)\n        for gen_id in generate_ids\n    ]\n\n    return \"\".join(preds)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T12:11:12.511799Z","iopub.execute_input":"2023-05-13T12:11:12.512164Z","iopub.status.idle":"2023-05-13T12:11:14.678091Z","shell.execute_reply.started":"2023-05-13T12:11:12.512135Z","shell.execute_reply":"2023-05-13T12:11:14.677122Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"question = pairs_df.iloc[69].question\nprint(\"Question: \",question)\nprint(\"Assistant: \",generate_question(question))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T12:15:13.740161Z","iopub.execute_input":"2023-05-13T12:15:13.740540Z","iopub.status.idle":"2023-05-13T12:15:33.548409Z","shell.execute_reply.started":"2023-05-13T12:15:13.740510Z","shell.execute_reply":"2023-05-13T12:15:33.547452Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Question:  Zakaj naslednja koda js natisne niz \"banana\" na konzoli?\nconst word = ('b' + 'a' + + 'a' + 'a' ).toLowerCase();\nconsole.log(beseda);\n?\nAssistant:  ›Ñ:'a';'b');'c'='d'+'*'' +'A'('B')'^'`^^``{'ba'}{`bash(`b',`a','f')){{}`}}#{#${$#}$$;$=$_$($);$||`|'{\"a\"'s'$`;`'#`#'\"##',#\"\"$\";#,#.#(#){(\"b\");};}.$},'n':#;{|}|{\\{={*}(});{^}=`c`s',}'x'>'<{<}<<#</#><$\\$->`<`$<=\\`*`**`\n","output_type":"stream"}]},{"cell_type":"code","source":"def continue_run(checkpoint='/kaggle/working/best-model.ckpt'):\n    df_train, df_test = train_test_split(pairs_df,test_size = 0.2, random_state=100)\n    dataload = T5DataLoad(df_train,df_test)\n    dataload.setup()\n    device = DEVICE\n    model = T5Model.load_from_checkpoint(checkpoint)\n    #model.to(device)\n    \n    checkpoint = ModelCheckpoint(\n        dirpath=\"/kaggle/working\",\n        filename='best-model',\n        save_top_k=2,\n        verbose=True,\n        monitor=\"val_loss\",\n        mode=\"min\"\n    )\n    trainer = pl.Trainer(\n        callbacks = checkpoint,\n        max_epochs= 1,\n        devices=2,\n        accelerator=\"auto\"\n    )\n    trainer.fit(model, dataload)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T12:17:46.205007Z","iopub.execute_input":"2023-05-13T12:17:46.205706Z","iopub.status.idle":"2023-05-13T12:17:46.211825Z","shell.execute_reply.started":"2023-05-13T12:17:46.205672Z","shell.execute_reply":"2023-05-13T12:17:46.210847Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"continue_run()","metadata":{"execution":{"iopub.status.busy":"2023-05-13T12:17:50.528685Z","iopub.execute_input":"2023-05-13T12:17:50.529157Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /kaggle/working exists and is not empty.\n  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:432: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n  warning_cache.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34741cd2c08445c69597aa6751b7dc29"}},"metadata":{}}]}]}