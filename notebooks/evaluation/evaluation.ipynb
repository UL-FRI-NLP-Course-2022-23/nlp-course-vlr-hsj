{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Luka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoModel, AutoTokenizer\n",
    "import nltk\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import *\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "nltk.download('punkt')\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = load_metric(\"rouge\")\n",
    "bert = load_metric(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge(decoded_preds, decoded_labels, prediction_lens):\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    # prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoints = [\n",
    "    \"cjvt/t5-sl-small\",\n",
    "    \"ls1906/t5-sl-small-finetuned-assistant\",\n",
    "    # \"cjvt/t5-sl-large\",\n",
    "    \"vh-student/t5-sl-large-oasst-pairs\",\n",
    "    \"vh-student/t5-sl-large-oasst-context\",\n",
    "    \"cjvt/gpt-sl-base\",\n",
    "    \"vh-student/gpt-sl-oasst1-pairs\",\n",
    "    \"vh-student/gpt-sl-oasst1-context\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First generated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5-SL-SMALL\n",
      "{'rouge1': 0.3379, 'rouge2': 0.0652, 'rougeL': 0.2437, 'rougeLsum': 0.3107, 'gen_len': 3.4974}\n",
      "{'Precision': 0.6246253625246194, 'Recall': 0.440937813881116, 'F1': 0.5145365299567198}\n",
      "\n",
      "T5-SL-SMALL-FINETUNED-ASSISTANT\n",
      "{'rouge1': 17.2297, 'rouge2': 4.0728, 'rougeL': 11.4752, 'rougeLsum': 15.7352, 'gen_len': 73.2593}\n",
      "{'Precision': 0.6693199219275744, 'Recall': 0.63366664484831, 'F1': 0.6491875981428684}\n",
      "\n",
      "T5-SL-LARGE-OASST-PAIRS\n",
      "{'rouge1': 14.7096, 'rouge2': 3.6051, 'rougeL': 10.3875, 'rougeLsum': 13.3069, 'gen_len': 60.1304}\n",
      "{'Precision': 0.6684416730118834, 'Recall': 0.6245725867237247, 'F1': 0.64394908616542}\n",
      "\n",
      "T5-SL-LARGE-OASST-CONTEXT\n",
      "{'rouge1': 17.9929, 'rouge2': 4.1677, 'rougeL': 14.1615, 'rougeLsum': 16.783, 'gen_len': 50.6636}\n",
      "{'Precision': 0.7225160922187016, 'Recall': 0.658557513531338, 'F1': 0.6862731942471684}\n",
      "\n",
      "GPT-SL-BASE\n",
      "{'rouge1': 15.0177, 'rouge2': 2.4444, 'rougeL': 9.1292, 'rougeLsum': 13.5454, 'gen_len': 162.5594}\n",
      "{'Precision': 0.5951044166271503, 'Recall': 0.6274400646992219, 'F1': 0.6096532117097806}\n",
      "\n",
      "GPT-SL-OASST1-PAIRS\n",
      "{'rouge1': 16.9017, 'rouge2': 2.6262, 'rougeL': 9.821, 'rougeLsum': 15.6108, 'gen_len': 162.5594}\n",
      "{'Precision': 0.6103136445558988, 'Recall': 0.6375802577825693, 'F1': 0.6223735233637003}\n",
      "\n",
      "GPT-SL-OASST1-CONTEXT\n",
      "{'rouge1': 14.7789, 'rouge2': 2.3987, 'rougeL': 8.8453, 'rougeLsum': 13.6471, 'gen_len': 202.3118}\n",
      "{'Precision': 0.6056029965200097, 'Recall': 0.6519947116485918, 'F1': 0.625987774996168}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_checkpoint in model_checkpoints:\n",
    "    # read local data depending on the model that it was generated with\n",
    "    model_name = model_checkpoint.split(\"/\")[-1]\n",
    "    data_path = f\"../../data/results/prompt_reply_pairs_1_generated_{split}_{model_name}.csv\"\n",
    "    data = pd.read_csv(data_path, sep=\";\")\n",
    "\n",
    "    decoded_labels = data[\"reply\"].to_list()\n",
    "    decoded_preds = data[\"generated\"].to_list()\n",
    "    prediction_lens = data[\"token_prediction_len\"].to_list()\n",
    "\n",
    "    print(model_name.upper())\n",
    "\n",
    "    # ROUGE\n",
    "    result_rouge = compute_rouge(decoded_preds, decoded_labels, prediction_lens)\n",
    "    print(result_rouge)\n",
    "\n",
    "    # BERTSCORE\n",
    "    result_bert = bert.compute(predictions=decoded_preds, references=decoded_labels, lang=\"sl\")\n",
    "    result_bert = {\"Precision\": np.array(result_bert[\"precision\"]).mean(), \"Recall\": np.array(result_bert[\"recall\"]).mean(), \"F1\": np.array(result_bert[\"f1\"]).mean()}\n",
    "    print(result_bert)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
