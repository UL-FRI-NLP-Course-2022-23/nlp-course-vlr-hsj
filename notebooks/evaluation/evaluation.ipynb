{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Luka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoModel, AutoTokenizer\n",
    "import nltk\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import *\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "nltk.download('punkt')\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = load_metric(\"rouge\")\n",
    "bert = load_metric(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge(decoded_preds, decoded_labels, prediction_lens):\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    # prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5-SL-SMALL\n",
      "{'rouge1': 0.3373, 'rouge2': 0.0647, 'rougeL': 0.2434, 'rougeLsum': 0.3086, 'gen_len': 3.4974}\n",
      "{'Precision': 0.624625362267861, 'Recall': 0.4409378152504945, 'F1': 0.5145365310693398}\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"cjvt/t5-sl-small\"\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "data_path = f\"../../data/results/prompt_reply_pairs_1_generated_{split}_{model_name}.csv\"\n",
    "\n",
    "data = pd.read_csv(data_path, sep=\";\")\n",
    "# display(data)\n",
    "\n",
    "decoded_labels = data[\"reply\"].to_list()\n",
    "decoded_preds = data[\"generated\"].to_list()\n",
    "prediction_lens = data[\"token_prediction_len\"].to_list()\n",
    "quantitative_data = pd.DataFrame({\"decoded_preds\": data[\"generated\"], \"decoded_labels\": data[\"reply\"], \"prediction_lens\": data[\"token_prediction_len\"]})\n",
    "# display(quantitative_data)\n",
    "\n",
    "print(model_name.upper())\n",
    "\n",
    "# ROUGE\n",
    "result_rouge = compute_rouge(decoded_preds, decoded_labels, prediction_lens)\n",
    "print(result_rouge)\n",
    "\n",
    "# BERTSCORE\n",
    "result_bert = bert.compute(predictions=decoded_preds, references=decoded_labels, lang=\"sl\")\n",
    "result_bert = {\"Precision\": np.array(result_bert[\"precision\"]).mean(), \"Recall\": np.array(result_bert[\"recall\"]).mean(), \"F1\": np.array(result_bert[\"f1\"]).mean()}\n",
    "print(result_bert)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 small finetuned pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5-SL-SMALL-FINETUNED-ASSISTANT\n",
      "{'rouge1': 17.2245, 'rouge2': 4.0757, 'rougeL': 11.48, 'rougeLsum': 15.7309, 'gen_len': 73.3327}\n",
      "{'Precision': 0.6697491393517225, 'Recall': 0.6337999124588111, 'F1': 0.649464008190693}\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"ls1906/t5-sl-small-finetuned-assistant\"\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "data_path = f\"../../data/results/prompt_reply_pairs_1_generated_{split}_{model_name}.csv\"\n",
    "\n",
    "data = pd.read_csv(data_path, sep=\";\")\n",
    "# display(data)\n",
    "\n",
    "decoded_labels = data[\"reply\"].to_list()\n",
    "decoded_preds = data[\"generated\"].to_list()\n",
    "prediction_lens = data[\"token_prediction_len\"].to_list()\n",
    "quantitative_data = pd.DataFrame({\"decoded_preds\": data[\"generated\"], \"decoded_labels\": data[\"reply\"], \"prediction_lens\": data[\"token_prediction_len\"]})\n",
    "# display(quantitative_data)\n",
    "\n",
    "print(model_name.upper())\n",
    "\n",
    "# ROUGE\n",
    "result_rouge = compute_rouge(decoded_preds, decoded_labels, prediction_lens)\n",
    "print(result_rouge)\n",
    "\n",
    "# BERTSCORE\n",
    "result_bert = bert.compute(predictions=decoded_preds, references=decoded_labels, lang=\"sl\")\n",
    "result_bert = {\"Precision\": np.array(result_bert[\"precision\"]).mean(), \"Recall\": np.array(result_bert[\"recall\"]).mean(), \"F1\": np.array(result_bert[\"f1\"]).mean()}\n",
    "print(result_bert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
