@article{lhoest2021datasets,
  title={Datasets: A community library for natural language processing},
  author={Lhoest, Quentin and del Moral, Albert Villanova and Jernite, Yacine and Thakur, Abhishek and von Platen, Patrick and Patil, Suraj and Chaumond, Julien and Drame, Mariama and Plu, Julien and Tunstall, Lewis and others},
  journal={arXiv preprint arXiv:2109.02846},
  year={2021}
}

@article{roots,
author = {Laurençon, Hugo and Saulnier, Lucile and Wang, Thomas and Akiki, Christopher and Moral, Albert and Scao, Teven and Werra, Leandro and Mou, Chenghao and Ponferrada, Eduardo and Nguyen, Huu and Frohberg, Jörg and Šaško, Mario and Lhoest, Quentin and McMillan-Major, Angelina and Dupont, Gerard and Biderman, Stella and Rogers, Anna and allal, Loubna and Toni, Francesco and Jernite, Yacine},
year = {2023},
month = {03},
pages = {},
title = {The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset}
}

@article{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

@article{ulvcar2021sloberta,
  title={SloBERTa: Slovene monolingual large pretrained masked language model},
  author={Ul{\v{c}}ar, Matej and Robnik-{\v{S}}ikonja, Marko},
  journal={Proceedings of SI-KDD within the Information Society 2021},
  pages={17--20},
  year={2021}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@INPROCEEDINGS{tv_series_subtitles,
  author={Zhang, Leilan and Zhou, Qiang},
  booktitle={2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={Automatically Annotate TV Series Subtitles for Dialogue Corpus Construction}, 
  year={2019},
  volume={},
  number={},
  pages={1029-1035},
  doi={10.1109/APSIPAASC47483.2019.9023129}
}

@article{bach2022promptsource,
  title={Promptsource: An integrated development environment and repository for natural language prompts},
  author={Bach, Stephen H and Sanh, Victor and Yong, Zheng-Xin and Webson, Albert and Raffel, Colin and Nayak, Nihal V and Sharma, Abheesht and Kim, Taewoon and Bari, M Saiful and Fevry, Thibault and others},
  journal={arXiv preprint arXiv:2202.01279},
  year={2022}
}

@article{Verdonik2013,
  doi = {10.1007/s10579-013-9216-5},
  url = {https://doi.org/10.1007/s10579-013-9216-5},
  year = {2013},
  month = jan,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {47},
  number = {4},
  pages = {1031--1048},
  author = {Darinka Verdonik and Iztok Kosem and Ana Zwitter Vitez and Simon Krek and Marko Stabej},
  title = {Compilation,  transcription and usage of a reference speech corpus: the case of the Slovene corpus {GOS}},
  journal = {Language Resources and Evaluation}
}

@article{wang2019superglue,
  title={Superglue: A stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

 @misc{11356/1320,
 title = {Corpus of Written Standard Slovene Gigafida 2.0},
 author = {Krek, Simon and Erjavec, Toma{\v z} and Repar, Andra{\v z} and {\v C}ibej, Jaka and Arhar Holdt, {\v S}pela and Gantar, Polona and Kosem, Iztok and Robnik-{\v S}ikonja, Marko and Ljube{\v s}i{\'c}, Nikola and Dobrovoljc, Kaja and Laskowski, Cyprian and Gr{\v c}ar, Miha and Holozan, Peter and {\v S}uster, Simon and Gorjanc, Vojko and Stabej, Marko and Logar, Nata{\v s}a},
 url = {http://hdl.handle.net/11356/1320},
 note = {Slovenian language resource repository {CLARIN}.{SI}},
 issn = {2820-4042},
 year = {2019} }

 @inproceedings{kosem2011slovenian,
  title={How do Slovenian primary and secondary school students write and what their teachers correct: A corpus of student writing},
  author={Kosem, Iztok and Rozman, Toma{\v{z}} and Stritar, Mateja},
  booktitle={Proceedings of Corpus Linguistics Conference},
  year={2011},
  month={July},
  pages={20--22}
}

@misc{logar2022unified,
      title={Unified Question Answering in Slovene}, 
      author={Katja Logar and Marko Robnik-Šikonja},
      year={2022},
      eprint={2211.09159},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

 @misc{11356/1736,
 title = {Neural Machine Translation model for Slovene-English language pair {RSDO}-{DS4}-{NMT} 1.2.6},
 author = {Lebar Bajec, Iztok and Repar, Andra{\v z} and Dem{\v s}ar, Jure and Bajec, {\v Z}an and Rizvi{\v c}, Mitja and Kumper{\v s}{\v c}ak, Borut and Bajec, Marko},
 url = {http://hdl.handle.net/11356/1736},
 note = {Slovenian language resource repository {CLARIN}.{SI}},
 copyright = {Apache License 2.0},
 issn = {2820-4042},
 year = {2022} }

 @misc{deepl,
  title = {{DeepL Translator}},
  author = {{DeepL GmbH}},
  howpublished = {\url{https://www.deepl.com/translator}},
  year = {Accessed 2023, March 21}
}

@article{nllb2022,
  title={No Language Left Behind: Scaling Human-Centered Machine Translation},
  author={{NLLB Team} and Costa-jussà, Marta R. and Cross, James and Çelebi, Onur and Elbayad, Maha and Heafield, Kenneth and Heffernan, Kevin and Kalbassi, Elahe and Lam, Janice and Licht, Daniel and Maillard, Jean and Sun, Anna and Wang, Skyler and Wenzek, Guillaume and Youngblood, Al and Akula, Bapi and Barrault, Loic and Mejia-Gonzalez, Gabriel and Hansanti, Prangthip and Hoffman, John and Jarrett, Semarley and Sadagopan, Kaushik Ram and Rowe, Dirk and Spruit, Shannon and Tran, Chau and Andrews, Pierre and Ayan, Necip Fazil and Bhosale, Shruti and Edunov, Sergey and Fan, Angela and Gao, Cynthia and Goswami, Vedanuj and Guzmán, Francisco and Koehn, Philipp and Mourachko, Alexandre and Ropers, Christophe and Saleem, Safiyyah and Schwenk, Holger and Wang, Jeff},
  year={2022}
}

@misc{google-translate,
  title = {{Google Translate}},
  author = {{Google LLC}},
  howpublished = {\url{https://translate.google.com/?hl=sl}},
  year = {Accessed 2023, March 21}
}

@online{deep_transaltor,
  title={deep-translator 1.10.1},
  url={https://pypi.org/project/deep-translator/},
  urldate = {2023-03-21}, 
  publisher={Nidhal Bacc}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@misc{touvron2023llama,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2022selfinstruct,
      title={Self-Instruct: Aligning Language Model with Self Generated Instructions}, 
      author={Yizhong Wang and Yeganeh Kordi and Swaroop Mishra and Alisa Liu and Noah A. Smith and Daniel Khashabi and Hannaneh Hajishirzi},
      year={2022},
      eprint={2212.10560},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}